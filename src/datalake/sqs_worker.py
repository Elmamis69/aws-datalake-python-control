"""
SQS Worker - Procesador Autom√°tico de Archivos

Este m√≥dulo implementa un worker que:
1. Escucha continuamente mensajes de una cola SQS
2. Procesa archivos cuando recibe notificaciones
3. Maneja reintentos autom√°ticos en caso de errores
4. Elimina mensajes procesados exitosamente de la cola
5. Env√≠a m√©tricas a CloudWatch para monitoreo

El worker es el coraz√≥n del procesamiento autom√°tico del Data Lake.
Cuando se sube un archivo a S3 RAW, se env√≠a un mensaje a SQS,
y este worker lo procesa autom√°ticamente.

Uso t√≠pico:
    from sqs_worker import run_sqs_worker
    
    def procesar_archivo(mensaje):
        # L√≥gica de procesamiento
        return True  # True si exitoso
    
    run_sqs_worker(
        queue_url="https://sqs.region.amazonaws.com/account/queue",
        handle_message=procesar_archivo
    )
"""
import time
import logging
import boto3
from typing import Callable, Optional
from datetime import datetime

logger = logging.getLogger("sqs_worker")
logging.basicConfig(level=logging.INFO)

def run_sqs_worker(
    queue_url: str,
    session: Optional[boto3.Session] = None,
    handle_message: Optional[Callable[[dict], bool]] = None,
    poll_interval: int = 10,
    max_retries: int = 3,
    max_empty_polls: int = None,
    enable_metrics: bool = True
):
    """
    Worker principal para consumir mensajes de SQS y procesar eventos de archivos
    
    Este worker implementa un patr√≥n de polling continuo:
    - Consulta la cola SQS cada poll_interval segundos
    - Procesa mensajes usando la funci√≥n handle_message
    - Reintenta autom√°ticamente en caso de errores
    - Se detiene despu√©s de max_empty_polls consultas vac√≠as (opcional)
    - Env√≠a m√©tricas a CloudWatch para monitoreo (opcional)
    
    Args:
        queue_url (str): URL completa de la cola SQS
        session (boto3.Session, optional): Sesi√≥n AWS personalizada
        handle_message (callable, optional): Funci√≥n que procesa cada mensaje.
                                           Debe retornar True si fue exitoso.
        poll_interval (int): Segundos entre consultas a la cola
        max_retries (int): N√∫mero de reintentos por mensaje fallido
        max_empty_polls (int): M√°ximo de consultas vac√≠as antes de terminar.
                              None = ejecutar indefinidamente
        enable_metrics (bool): Habilitar env√≠o de m√©tricas a CloudWatch
    
    Returns:
        None: El worker ejecuta hasta ser interrumpido o alcanzar max_empty_polls
    """
    sqs = (session or boto3).client('sqs')
    logger.info(f"üöÄ Iniciando worker SQS en {queue_url}")
    logger.info(f"‚öôÔ∏è  Configuraci√≥n: poll_interval={poll_interval}s, max_retries={max_retries}")
    
    # Inicializar m√©tricas de CloudWatch
    metrics = None
    if enable_metrics:
        try:
            from src.cloudwatch_monitor import CloudWatchMonitor, DataLakeMetrics
            monitor = CloudWatchMonitor()
            metrics = DataLakeMetrics(monitor)
            logger.info("üìä M√©tricas de CloudWatch habilitadas")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è No se pudieron habilitar m√©tricas: {e}")
    
    empty_polls = 0
    messages_received = 0
    messages_processed = 0
    
    while True:
        # Consultar cola SQS con long polling (WaitTimeSeconds=20)
        # Esto reduce costos y mejora la eficiencia
        resp = sqs.receive_message(
            QueueUrl=queue_url,
            MaxNumberOfMessages=1,  # Procesar de a uno para mejor control
            WaitTimeSeconds=20      # Long polling - espera hasta 20s por mensajes
        )
        messages = resp.get('Messages', [])
        messages_received += len(messages)
        
        if not messages:
            empty_polls += 1
            logger.info(f"üì≠ No hay mensajes ({empty_polls}/{max_empty_polls or '‚àû'})")
            
            # Terminar si se alcanza el l√≠mite de consultas vac√≠as
            if max_empty_polls and empty_polls >= max_empty_polls:
                logger.info("üõë M√°ximo de polls vac√≠os alcanzado. Terminando worker.")
                break
                
            time.sleep(poll_interval)
            continue
        
        # Resetear contador si hay mensajes
        empty_polls = 0
        
        # Procesar cada mensaje
        for msg in messages:
            receipt = msg['ReceiptHandle']  # Necesario para eliminar el mensaje
            body = msg['Body']              # Contenido del mensaje (ubicaci√≥n del archivo)
            success = False
            start_time = datetime.utcnow()
            
            # Reintentos autom√°ticos en caso de error
            for attempt in range(1, max_retries+1):
                try:
                    logger.info(f"üì® Procesando mensaje (intento {attempt}/{max_retries}): {body}")
                    
                    if handle_message:
                        success = handle_message(msg)
                    else:
                        # Comportamiento por defecto: solo loggear
                        logger.info(f"üìÑ Mensaje recibido: {body}")
                        success = True
                        
                    if success:
                        # Eliminar mensaje de la cola solo si se proces√≥ exitosamente
                        sqs.delete_message(QueueUrl=queue_url, ReceiptHandle=receipt)
                        logger.info("‚úÖ Mensaje procesado y eliminado de la cola.")
                        messages_processed += 1
                        
                        # Registrar m√©tricas de √©xito
                        if metrics:
                            processing_time = (datetime.utcnow() - start_time).total_seconds()
                            metrics.record_file_processed(
                                file_size=len(body),  # Aproximaci√≥n
                                processing_time=processing_time,
                                status='SUCCESS'
                            )
                        break
                        
                except Exception as e:
                    logger.error(f"‚ùå Error procesando mensaje (intento {attempt}): {e}")
                    if attempt < max_retries:
                        time.sleep(2)  # Esperar antes del siguiente intento
                    
            if not success:
                logger.warning(f"‚ö†Ô∏è  No se pudo procesar el mensaje tras {max_retries} intentos.")
                logger.warning("   El mensaje permanecer√° en la cola y ser√° reintentado m√°s tarde.")
                
                # Registrar m√©tricas de error
                if metrics:
                    processing_time = (datetime.utcnow() - start_time).total_seconds()
                    metrics.record_file_processed(
                        file_size=len(body),
                        processing_time=processing_time,
                        status='ERROR'
                    )
        
        # Registrar m√©tricas de SQS al final de cada ciclo
        if metrics and messages_received > 0:
            metrics.record_sqs_activity(messages_received, messages_processed)
            # Reset counters
            messages_received = 0
            messages_processed = 0
